{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e590b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac181494",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural Language Processing is the subfield of linguistic, computer science and artificial intelligence concerned with the interaction between human and computer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c5406ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is the subfield of linguistic computer science and artificial intelligence concerned with the interaction between human and computer\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "filtered_text = re.sub(r'[^\\w\\s]','',text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3b8186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'is', 'the', 'subfield', 'of', 'linguistic', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interaction', 'between', 'human', 'and', 'computer']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(filtered_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bd1b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [x for x in tokens if x.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e469250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('subfield', 'VBD'), ('linguistic', 'JJ'), ('computer', 'NN'), ('science', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('interaction', 'NN'), ('human', 'JJ'), ('computer', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagged = pos_tag(filtered_tokens)\n",
    "print(pos_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa80e488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natur', 'languag', 'process', 'subfield', 'linguist', 'comput', 'scienc', 'artifici', 'intellig', 'concern', 'interact', 'human', 'comput']\n"
     ]
    }
   ],
   "source": [
    "p = PorterStemmer()\n",
    "stem = [p.stem(x) for x in filtered_tokens]\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "138fc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "l = WordNetLemmatizer()\n",
    "lemma = [l.lemmatize(x) for x in filtered_tokens]\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d07e36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(x):\n",
    "    if x.startswith('V'):\n",
    "        return 'v'\n",
    "    elif x.startswith('R'):\n",
    "        return 'r'\n",
    "    elif x.startswith('J'):\n",
    "        return 'a'\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b52aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'subfield', 'linguistic', 'computer', 'science', 'artificial', 'intelligence', 'concern', 'interaction', 'human', 'computer']\n"
     ]
    }
   ],
   "source": [
    "l = WordNetLemmatizer()\n",
    "lemma = [l.lemmatize(x,pos(w)) for x,w in pos_tagged]\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52610a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef1464cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \" \".join(lemma)\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "tfidf_matrix = tv.fit_transform([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e83a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial --->  0.2581988897471611\n",
      "computer --->  0.5163977794943222\n",
      "concern --->  0.2581988897471611\n",
      "human --->  0.2581988897471611\n",
      "intelligence --->  0.2581988897471611\n",
      "interaction --->  0.2581988897471611\n",
      "language --->  0.2581988897471611\n",
      "linguistic --->  0.2581988897471611\n",
      "natural --->  0.2581988897471611\n",
      "processing --->  0.2581988897471611\n",
      "science --->  0.2581988897471611\n",
      "subfield --->  0.2581988897471611\n"
     ]
    }
   ],
   "source": [
    "features = tv.get_feature_names()\n",
    "\n",
    "tfidf_score = dict(zip(features, tfidf_matrix.toarray()[0]))\n",
    "\n",
    "for word, score in tfidf_score.items():\n",
    "    print(f\"{word} --->  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "241d561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial --->  0.2581988897471611\n",
      "computer --->  0.5163977794943222\n",
      "concern --->  0.2581988897471611\n",
      "human --->  0.2581988897471611\n",
      "intelligence --->  0.2581988897471611\n",
      "interaction --->  0.2581988897471611\n",
      "language --->  0.2581988897471611\n",
      "linguistic --->  0.2581988897471611\n",
      "natural --->  0.2581988897471611\n",
      "processing --->  0.2581988897471611\n",
      "science --->  0.2581988897471611\n",
      "subfield --->  0.2581988897471611\n"
     ]
    }
   ],
   "source": [
    "data = \" \".join(lemma)\n",
    "\n",
    "tv = TfidfVectorizer(use_idf=True)\n",
    "tfidf_matrix = tv.fit_transform([data])\n",
    "features = tv.get_feature_names()\n",
    "\n",
    "tfidf_score = dict(zip(features, tfidf_matrix.toarray()[0]))\n",
    "\n",
    "for word, score in tfidf_score.items():\n",
    "    print(f\"{word} --->  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "357fcfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial --->  0.2581988897471611\n",
      "computer --->  0.5163977794943222\n",
      "concern --->  0.2581988897471611\n",
      "human --->  0.2581988897471611\n",
      "intelligence --->  0.2581988897471611\n",
      "interaction --->  0.2581988897471611\n",
      "language --->  0.2581988897471611\n",
      "linguistic --->  0.2581988897471611\n",
      "natural --->  0.2581988897471611\n",
      "processing --->  0.2581988897471611\n",
      "science --->  0.2581988897471611\n",
      "subfield --->  0.2581988897471611\n"
     ]
    }
   ],
   "source": [
    "data = \" \".join(lemma)\n",
    "\n",
    "tv = TfidfVectorizer(use_idf=False)\n",
    "tfidf_matrix = tv.fit_transform([data])\n",
    "features = tv.get_feature_names()\n",
    "\n",
    "tfidf_score = dict(zip(features, tfidf_matrix.toarray()[0]))\n",
    "\n",
    "for word, score in tfidf_score.items():\n",
    "    print(f\"{word} --->  {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
